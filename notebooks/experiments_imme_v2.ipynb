{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd3232-8a66-489f-940b-38850bf7d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sharpness.dataloader import generate_synthetic_data, load_data, synthetic_f\n",
    "from sharpness.transforms import apply_transform, transform_d\n",
    "from sharpness.metric_list import metric_f, single_metrics\n",
    "from sharpness import compute_metric_globally, compute_metric_locally, compute_all_metrics_globally, compute_all_metrics_locally\n",
    "from sharpness.benchmark import visualize, heatmap_visualize\n",
    "\n",
    "# Import low level functions:\n",
    "from sharpness.dataloader import *\n",
    "from sharpness.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a20f7b-1fd8-4376-b418-0f884d46279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "def calc_min_max_while_dealing_with_nans( min_array, max_array ):\n",
    "    # This is an auxiliary function for value_range_for_image_set. \n",
    "    # Input:  min_array and max_array and numpy arrays that may contain lots of NaNs.\n",
    "    # Output: my_min and my_max are the min of min_array and the max of max_array, taking NaNs into account.\n",
    "\n",
    "    ##### Calc min while dealing with NaNs #####\n",
    "    min_n_valid = sum( np.isnan(min_array) == False )  # Number of valid entries    \n",
    "    if min_n_valid == 0:  # all values are NaNs\n",
    "        my_min = float(\"nan\")  # If ALL values are NaNs, then manually assign NaN  \n",
    "    else: # at least one value is not NaN \n",
    "        my_min = np.nanmin( min_array )  # nanmin ignores NaNs, as long at least one value is not NaN\n",
    "    \n",
    "    ##### Calc max while dealing with NaNs #####\n",
    "    max_n_valid = sum( np.isnan(max_array) == False )\n",
    "    if max_n_valid == 0:  \n",
    "        my_max = float(\"nan\")  # If ALL values are NaNs, then manually assign NaN\n",
    "    else: # at least one value is not NaN \n",
    "        my_max = np.nanmax( max_array )  # nanmin ignores NaNs, as long at least one value is not NaN\n",
    "    \n",
    "    return( my_min, my_max )\n",
    "    \n",
    "##############################################################\n",
    "def value_range_for_image_set( image_set_keys, image_set_dict ):\n",
    "    # We often want a set of images to have the same color bar. \n",
    "    # This function calculates a suitable range of values across all images in the given set. \n",
    "    # Input: \n",
    "    #   image_set_dict is a dictionary with (img, img_string) tuples. \n",
    "    #   image_set_keys contains the keys for image_set_dict.\n",
    "    \n",
    "    # To calculate (cmin,cmax) across all images, first extract min and max for all individual images\n",
    "    # and store in arrays, min_array, max_array.\n",
    "    \n",
    "    min_array = np.empty( len(image_set_keys) )\n",
    "    max_array = np.empty( len(image_set_keys) )\n",
    "    for image_counter, image_key in enumerate(image_set_keys):\n",
    "        (img, img_string) = image_set_dict[image_key]\n",
    "        min_array[image_counter] = np.min( img ) # store min value in array - to calc uniform color scale\n",
    "        max_array[image_counter] = np.max( img ) # store max value in array - to calc uniform color scale\n",
    "\n",
    "    # Calculate uniform range for color scale across all images using auxiliary function.\n",
    "    cmin_uniform, cmax_uniform = calc_min_max_while_dealing_with_nans( min_array, max_array )\n",
    "    return( cmin_uniform, cmax_uniform )\n",
    "    \n",
    "##############################################################\n",
    "def apply_univariate_metrics( selected_metrics, image_dict, selected_image_keys, base_image_key, want_uniform_color_scale_per_metric, filename_prefix ):\n",
    "\n",
    "    # Apply univariate metrics to all input images, generate heatmaps, and save image.\n",
    "    # Inputs: \n",
    "    #    selected_metrics:  which metrics to apply\n",
    "    #    image_dict:  dictionary with images we want to apply metrics to\n",
    "    #    selected_image_keys:  keys of those images to apply metrics\n",
    "    #    base_image_key:  key of the primary image that provides filename for output file\n",
    "    #    want_uniform_color_scale_per_metric:  \n",
    "    #         For each metric: should all heatmaps for the metric use identical color bar, or inidividual color bars?\n",
    "    #\n",
    "    # Output: \n",
    "    #   A single plot (on screen and saved to file) that shows\n",
    "    #      First row:  all input images\n",
    "    #      Second to last row:  heatmaps for all images for one metric per row\n",
    "    #\n",
    "    \n",
    "    print('\\n##############################\\n     Univariate metrics\\n')\n",
    "    print('     min_value and max_value of each heatmap are printed underneath each panel.')\n",
    "    print('     Note: color maps for heatmaps vary greatly.  Go from WHITE = min(0,min_value) to DARK GREEN = (max_value).')\n",
    "    print('##############################\\n\\n')\n",
    "\n",
    "    # Create a figure with subplots: columns represent transformations, rows represent metrics\n",
    "    n_cols = len(selected_image_keys)\n",
    "    n_rows = len(selected_metrics) + 1 # metrics, plus one row for original images\n",
    "    cm = 1/2.54  # conversion factor from inches (default unit) to centimeters\n",
    "    fig, axs = plt.subplots(\n",
    "        ncols=n_cols, nrows= n_rows,  \n",
    "        figsize= ( n_cols * 4, n_rows * 4), \n",
    "        sharex=\"col\", sharey=\"row\"\n",
    "    )\n",
    "\n",
    "    ######### FIRST ROW:  Plot original images \n",
    "    \n",
    "    # Prep: calculate uniform cmin and cmax for first row (if desired)\n",
    "    if want_uniform_color_scale_per_metric:  \n",
    "        for image_counter, image_key in enumerate(selected_image_keys):\n",
    "            cmin_uniform, cmax_uniform = value_range_for_image_set( selected_image_keys, image_dict )\n",
    "\n",
    "    # Plot first row\n",
    "    for image_counter, image_key in enumerate(selected_image_keys):        \n",
    "        (img, img_string) = image_dict[image_key]    # Get image to print      \n",
    "        if want_uniform_color_scale_per_metric:\n",
    "            (cmin, cmax) = (cmin_uniform, cmax_uniform) \n",
    "        else:\n",
    "            (cmin, cmax) = ( img.min(), img.max() )\n",
    "        i_row = 0\n",
    "        i_col = image_counter\n",
    "        axs[i_row][i_col].imshow(img, clim = (np.nanmin([0.0,cmin]), cmax), cmap='gray' )\n",
    "        axs[i_row][i_col].set_title(img_string)\n",
    "        axs[i_row][i_col].set_xlabel(f'Min: {img.min():.2f}   Mean: {img.mean():.2f}   Max: {img.max():.2f} ')\n",
    "\n",
    "        \n",
    "    #### ALL OTHER ROWS: Plot heatmaps for all images (one metric per row)\n",
    "    \n",
    "    # For each metric (=each row)\n",
    "    for metric_counter, my_metric in enumerate(selected_metrics):\n",
    "\n",
    "        # For each metric: CALCULATE all heatmaps\n",
    "        img_row_dict = {}  # store all heatmaps for this metric in a dictionary        \n",
    "        for image_counter, image_key in enumerate(selected_image_keys):\n",
    "            (img, img_string) = image_dict[image_key]  # Get input image\n",
    "    \n",
    "            ##### Calculate heatmaps for all images for this metric\n",
    "            # Note that these metrics are univariate, so we only feed in one image and only care about first heatmap returned.\n",
    "            img_heatmap, dummy_heatmap = compute_metric_locally(img, img, metric = my_metric)\n",
    "            # store all heatmaps for this metric in a dictionary\n",
    "            img_row_dict[image_key] = ( img_heatmap, img_string )\n",
    "\n",
    "        # Prep: calculate uniform cmin and cmax for this row (if desired)\n",
    "        if want_uniform_color_scale_per_metric:  \n",
    "            for image_counter, image_key in enumerate(selected_image_keys):\n",
    "                cmin_uniform, cmax_uniform = value_range_for_image_set( selected_image_keys, img_row_dict )\n",
    "                \n",
    "        # For each metric: PLOT all heatmaps\n",
    "        for image_counter, image_key in enumerate(selected_image_keys):\n",
    "\n",
    "            # retrieve heatmap for plotting\n",
    "            (img_heatmap, img_string) = img_row_dict[image_key]\n",
    "            \n",
    "            # Determine limits for color bar.  Note: min/max/mean values of heatmap are printed underneath each plot. \n",
    "            if ( want_uniform_color_scale_per_metric ):\n",
    "                (cmin, cmax) = (cmin_uniform, cmax_uniform) \n",
    "            else:\n",
    "                (cmin, cmax) = ( img_heatmap.min(), img_heatmap.max() )\n",
    "                \n",
    "            i_row = metric_counter+1\n",
    "            i_col = image_counter\n",
    "            axs[i_row][i_col].imshow(img_heatmap, clim=(np.nanmin([0.0,cmin]), cmax), cmap='Greens')\n",
    "            axs[i_row][i_col].set_title(f' Heatmap - {my_metric}')\n",
    "            axs[i_row][i_col].set_xlabel(f'Min: {img_heatmap.min():.2f}   Mean: {img_heatmap.mean():.2f}   Max: {img_heatmap.max():.2f} ')\n",
    "\n",
    "        \n",
    "    # Show the figure and save to file\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    (base_img, base_string) = image_dict[base_image_key]  # Get name of base image for filename\n",
    "    output_filename = f'OUTPUT/{filename_prefix}_{base_string}_Univariate.png';\n",
    "    print(f'Saving results to {output_filename}')\n",
    "    plt.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58d3c6-0b4b-4538-9a97-bc6b0edbc58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_bivariate_metrics( selected_metrics, image_dict, selected_image_keys, base_image_key, filename_prefix ):\n",
    "\n",
    "    print('\\n##############################\\n     Bivariate metrics\\n')\n",
    "    print('     min_value and max_value of each heatmap are printed underneath each panel.')\n",
    "    print('     Note: color map for heatmaps vary greatly.  Go from WHITE = min(0,min_value) to DARK GREEN = (max_value).')\n",
    "    print('##############################\\n\\n')\n",
    "\n",
    "    # Create a figure with subplots: columns represent images, rows represent metrics\n",
    "    n_cols = len(selected_image_keys)\n",
    "    n_rows = len(selected_metrics) + 1  # metrics, plus one row for original images\n",
    "    cm = 1/2.54  # conversion factor from inches (default unit) to centimeters\n",
    "    fig, axs = plt.subplots(\n",
    "        ncols=n_cols, nrows= n_rows,  \n",
    "        figsize= ( n_cols * 4, n_rows * 4),  # per image:  5 in width and height \n",
    "        sharex=\"col\", sharey=\"row\"\n",
    "    )\n",
    "    \n",
    "    # Create a figure with subplots: columns represent transformations, rows represent metrics\n",
    "    #fig, axs = plt.subplots(\n",
    "    #    #nrows= 1+ len(selected_metrics), ncols=len(selected_image_keys), figsize=(2 * len(selected_metrics), 16 * len(selected_image_keys)), sharex=\"col\", sharey=\"row\"\n",
    "    #    nrows= 1+ len(selected_metrics), ncols=len(selected_image_keys), figsize=(20, 50), sharex=\"col\", sharey=\"row\"\n",
    "    #)\n",
    "\n",
    "    # Use min and max of base image to scale first row of images\n",
    "    (base_img, base_string) = image_dict[base_image_key]\n",
    "    value_range_for_plotting = ( np.min(base_img), np.max(base_img) )\n",
    "    \n",
    "    for img_counter, img_key in enumerate(selected_image_keys):\n",
    "    \n",
    "        # Each transform defines one column\n",
    "        (img, img_string) = image_dict[img_key]\n",
    "    \n",
    "        # First row:  plot original image and transformed images\n",
    "        axs[0][img_counter].imshow(img, clim = value_range_for_plotting, cmap='gray' )\n",
    "        axs[0][img_counter].set_title(img_string)\n",
    "        axs[0][img_counter].set_xlabel(f'Min: {img.min():.2f}   Mean: {img.mean():.2f}   Max: {img.max():.2f} ')\n",
    "    \n",
    "        # All other rows:  show heatmaps for different metrics  (each metric gets one row)\n",
    "        for metric_counter, my_metric in enumerate(selected_metrics, start=1):\n",
    "            \n",
    "            img_heatmap = compute_metric_locally(base_img, img, metric = my_metric)\n",
    "            cmin = np.min( (img_heatmap.min(), 0) )\n",
    "            cmax = img_heatmap.max()\n",
    "            axs[metric_counter][img_counter].imshow(img_heatmap, clim=(cmin, cmax), cmap='Greens')\n",
    "            axs[metric_counter][img_counter].set_title(f' Heatmap - {my_metric}')\n",
    "            axs[metric_counter][img_counter].set_xlabel(f'Min: {img_heatmap.min():.2f}   Mean: {img_heatmap.mean():.2f}   Max: {img_heatmap.max():.2f} ')\n",
    "            \n",
    "    # Show the figure and save to file\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    output_filename = f'OUTPUT/{filename_prefix}_{base_string}_Bivariate.png';\n",
    "    print(f'Saving results to {output_filename}')\n",
    "    plt.savefig(output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707a332-b998-47e5-a780-0e6a38cc1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Prepare collection of base images to use\n",
    "########################################################\n",
    "\n",
    "def prepare_set_of_base_images( ):\n",
    "\n",
    "    ############ A) LOAD OBSERVED IMAGES ############\n",
    "    file_name_satellite = '../data/kh_ABI_C13.nc'      # Sample satellite image \n",
    "    file_name_radar = '../data/kh_MRMS_REFC.nc'        # Corresponding radar image\n",
    "    file_name_radar_CNN = '../data/kh_GREMLIN_REFC.nc' # Corresponding CNN estimate of radar (using satellite image as input)\n",
    "    \n",
    "    i_sample = 50  # Choose any sample\n",
    "    img_satellite = load_data(file_name_satellite, i_sample)\n",
    "    img_RADAR     = load_data(file_name_radar, i_sample)\n",
    "    img_RADAR_CNN = load_data(file_name_radar_CNN, i_sample)\n",
    "    \n",
    "    ############ B) CREATE SYNTHETIC IMAGES ###########\n",
    "    ############ Gaussian blobs\n",
    "    # Create six Gaussian blobs with exponentially increasing sigma values - to test the effect of varying sigma\n",
    "    n_pixels=256\n",
    "    center_x=40;     center_y=50;    sigma=1;    img1 = gaussian_blob(n_pixels, center_x, center_y, sigma)\n",
    "    center_x=40;     center_y=80;    sigma=2;    img2 = gaussian_blob(n_pixels, center_x, center_y, sigma)\n",
    "    center_x=40;     center_y=120;   sigma=4;    img3 = gaussian_blob(n_pixels, center_x, center_y, sigma)\n",
    "    center_x=40;     center_y=180;   sigma=8;    img4 = gaussian_blob(n_pixels, center_x, center_y, sigma)\n",
    "    center_x=160;    center_y=50;    sigma=16;   img5 = gaussian_blob(n_pixels, center_x, center_y, sigma)\n",
    "    center_x=160;    center_y=170;   sigma=32;   img6 = gaussian_blob(n_pixels, center_x, center_y, sigma)\n",
    "    # final image\n",
    "    img_synthetic_Gaussian = img1 + img2 + img3 + img4 + img5 + img6 \n",
    "    \n",
    "    ############ Sinusoidal grating - to test the effect of gentle transitions\n",
    "    n_pixels=256\n",
    "    wave_length_in_pixels=50\n",
    "    alpha_in_degrees=20\n",
    "    # final image\n",
    "    img_synthetic_sinusoidal = sinusoidal_grating(n_pixels, wave_length_in_pixels, alpha_in_degrees)\n",
    "    \n",
    "    ############ Single, narrow ridge - to test effect of sharp edges\n",
    "    n_pixels = 256\n",
    "    fraction = fraction=0.52\n",
    "    img_1 = black_white(n_pixels, fraction)\n",
    "    fraction = fraction=0.48\n",
    "    img_2 = black_white(n_pixels, fraction)\n",
    "    #final image\n",
    "    img_synthetic_ridge = img_2 - img_1\n",
    "    \n",
    "    ############ XOR fractal - contains lots of areas with different \"texture\"\n",
    "    n_pixels=256\n",
    "    img_synthetic_fractal = xor_fractal( n_pixels )\n",
    "    \n",
    "    # store all images and corresponding text in dictionary to be returned\n",
    "    image_collection_dict = {\n",
    "        'satellite'  : (img_satellite, \"Satellite\"),\n",
    "        'radar'      : (img_RADAR, \"Radar\"),\n",
    "        'radar_CNN'  : (img_RADAR_CNN, \"Radar_CNN\"),\n",
    "        'gaussian'   : (img_synthetic_Gaussian, \"Gaussian_blobs\"),\n",
    "        'sinusoidal' : (img_synthetic_sinusoidal, \"Sinusoidal\"),\n",
    "        'ridge'      : (img_synthetic_ridge, \"Ridge\"),\n",
    "        'fractal'    : (img_synthetic_fractal, \"Fractal\")\n",
    "    }\n",
    "\n",
    "    # print all images in collection we created\n",
    "    for img_counter, (key, (img, img_text)) in enumerate(image_collection_dict.items()):\n",
    "        plt.figure( img_counter )\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(img_text)\n",
    "        plt.xlabel(f'Min: {img.min():.3f}     Mean: {img.mean():.3f}     Max: {img.max():.3f} ')\n",
    "        plt.show()\n",
    "    \n",
    "    return( image_collection_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43109ac-36a3-49ef-9f31-db56cae4f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Define a set of various transformations to be applied to base image to get an idea of how measures differ.\n",
    "# This is also where parameters are chosen for the different transformations.\n",
    "#############################################################################\n",
    "\n",
    "def apply_wide_range_of_transforms_to_image( original_img, original_img_string ):\n",
    "    \n",
    "    # Apply transformation 100% of the time (randomness turned off)\n",
    "    rate = 1\n",
    "    \n",
    "    # Apply the Gaussian Blur to the image\n",
    "    my_transform_str = 'blur' # This works\n",
    "    blurr_sigma = 1   # Choose parameter\n",
    "    blurr_string = f'{\"Blurred (sigma=\"}{blurr_sigma:.2f}{\")\"}'\n",
    "    blurred_img = GaussianBlur(rate, sigma=blurr_sigma)(original_img)   # Why does this create a modified image even for sigma=0?\n",
    "    \n",
    "    # Add Gaussian Noise to image\n",
    "    my_transform_str = 'noise'\n",
    "    noise_sigma = 0.2   # Choose parameter\n",
    "    noise_string = f'{\"Noise added (sigma=\"}{noise_sigma:.2f}{\"* max)\"}'\n",
    "    noise_img = GaussianNoise(rate, noise=noise_sigma)(original_img)    # Why does this create a modified image even for noise=0?\n",
    "    \n",
    "    # Apply the Brightness adjustment transformation to the image\n",
    "    my_transform_str = 'brightness' # This works\n",
    "    brightness_factor = 0.5   # Choose parameter\n",
    "    brightness_string = f'{\"Brightness modified (factor=\"}{brightness_factor:.2f}{\")\"}'\n",
    "    brightness_img = AdjustBrightness(rate, brightness=brightness_factor)(original_img)\n",
    "    \n",
    "    # Crop image (TBC) - Lander, can you please fill in?\n",
    "    my_transform_str = 'crop' \n",
    "    # crop parameter\n",
    "    # crop_img = \n",
    "    # cropstring = \n",
    "    \n",
    "    # Apply the H-flip transformation to the image\n",
    "    my_transform_str = 'hflip' # This works\n",
    "    hflip_img = RandHorizontalFlip(rate)(original_img)\n",
    "    hflip_string = \"Flipped horizontally\"\n",
    "    \n",
    "    # Apply the V-flip transformation to the image\n",
    "    my_transform_str = 'vflip' # This works\n",
    "    vflip_img = RandVerticalFlip(rate)(original_img)\n",
    "    vflip_string = \"Flipped vertically\"\n",
    "    \n",
    "    # Store everything in a dictionary\n",
    "    transformed_image_dict = { \n",
    "        'original'   : (original_img, original_img_string), \n",
    "        'blur'       : (blurred_img, blurr_string),\n",
    "        'noise'      : (noise_img, noise_string),\n",
    "        'brightness' : (brightness_img, brightness_string),\n",
    "        #'crop'       : (crop_img, crop_string),    # still needs to be added!\n",
    "        # 'invert'    : (invert_img, invert_string),  # not yet defined.  Useful?\n",
    "        'hflip'      : (hflip_img, hflip_string), \n",
    "        'vflip'      : (vflip_img, vflip_string)\n",
    "    }\n",
    "\n",
    "    return( transformed_image_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea07897-46c9-48f4-b24d-fb55d1bc1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Step 1: Prepare set of base images and plot them\n",
    "base_image_dict = prepare_set_of_base_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf8f33-432e-4a88-8ac5-1930458bdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ EXPERIMENT 1: ############\n",
    "############ Apply a bunch of different transformations just to get a first feeling for how the metrics change ############\n",
    "\n",
    "####### Step 1: Select a single image, select and apply transformations which includes plotting resulting images.\n",
    "# Select base image: \n",
    "# Available choices: [ 'satellite', 'radar', 'radar_CNN', 'gaussian', 'sinusoidal', 'ridge', 'fractal' ]\n",
    "#base_image_key = 'satellite'\n",
    "\n",
    "#for base_image_key in [ 'satellite', 'radar', 'radar_CNN', 'gaussian', 'sinusoidal', 'ridge', 'fractal' ]:\n",
    "for base_image_key in [ 'satellite', 'gaussian' ]:\n",
    "    \n",
    "    print(f'\\n       Selected image for analysis:     {base_image_key}\\n')\n",
    "    \n",
    "    # Select transformations to apply\n",
    "    # Available transforms: [ 'original', 'hflip', 'vflip', 'brightness', 'blur', 'noise' ]\n",
    "    selected_transforms_keys = [ 'original', 'blur', 'noise', 'brightness', 'hflip', 'vflip' ]\n",
    "    \n",
    "    (original_img, original_img_string) = base_image_dict[base_image_key]\n",
    "    # Generate transformed images\n",
    "    transformed_image_dict = apply_wide_range_of_transforms_to_image( original_img, original_img_string )\n",
    "    \n",
    "    ####### Step 2: Apply selected transforms to origimal image and plot results\n",
    "    \n",
    "    # Metrics\n",
    "    # Available bivariate: ['mse', 'mae', 'rmse', 'psnr', 'ncc', 'grad-ds', 'grad-rmse', 'laplace-rmse', 'hist-int', 'hog-pearson', 'fourier-similarity', 'wavelet-similarity']\n",
    "    \n",
    "    ####### Step 2a) Apply univariate metrics and plot heatmaps\n",
    "    \n",
    "    # Available univariate metrics: [\"mgm\", \"s1\", \"tv\", \"grad-tv\", \"fourier-tv\", \"wavelet-tv\"]\n",
    "    selected_metrics_univariate = [ \"mgm\", \"tv\", \"grad-tv\", \"s1\", \"fourier-tv\", \"wavelet-tv\"  ]\n",
    "    original_image_key = 'original'\n",
    "    want_uniform_color_scale_per_metric = True\n",
    "    filename_prefix = 'Exp_1b_GENERIC'\n",
    "    apply_univariate_metrics( selected_metrics_univariate, transformed_image_dict, selected_transforms_keys, original_image_key, want_uniform_color_scale_per_metric, filename_prefix )\n",
    "    \n",
    "    \n",
    "    ####### Step 2b) Apply bivariate metrics and plot heatmaps\n",
    "    \n",
    "    # Available bivariate metrics: ['mse', 'mae', 'rmse', 'psnr', 'ncc', 'grad-ds', 'grad-rmse', 'laplace-rmse', 'hist-int', 'hog-pearson', 'fourier-similarity', 'wavelet-similarity']\n",
    "    # Lander - Let's add SSIM\n",
    "    #bi_metrics_set_1 = ['mse', 'mae', 'rmse', 'psnr', 'ncc'] # Difference in pixel space \n",
    "    #bi_metrics_set_2 = ['hist-int', 'hog-pearson'] # Difference in histogram space?\n",
    "    #bi_metrics_set_3 = ['grad-ds', 'grad-rmse', 'laplace-rmse']   # Difference in gradient space\n",
    "    #bi_metrics_set_4 = ['fourier-similarity', 'wavelet-similarity'] # Difference in spectral space\n",
    "    selected_metrics_bivariate = ['mse', 'mae', 'rmse', 'psnr', 'ncc', 'grad-ds', 'grad-rmse', 'laplace-rmse', 'hist-int', 'hog-pearson', 'fourier-similarity', 'wavelet-similarity']\n",
    "    # Removed metric 'fourier-similarity' temporarily, so that it doesn't throw an error until fixed.\n",
    "    selected_metrics_bivariate = ['mse', 'mae', 'rmse', 'psnr', 'ncc', 'grad-ds', 'grad-rmse', 'laplace-rmse', 'hist-int', 'hog-pearson', 'wavelet-similarity']\n",
    "\n",
    "    original_image_key = 'original'\n",
    "    filename_prefix = 'Exp_1b_GENERIC_'\n",
    "    apply_bivariate_metrics( selected_metrics_bivariate, transformed_image_dict, selected_transforms_keys, original_image_key, filename_prefix )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338a09f-74aa-4377-9ae3-8cf616c5ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ EXPERIMENT 2: ############\n",
    "############ COMPARE Observed radar to CNN-generated radar image (from GREMLIN) ############\n",
    "\n",
    "############ LOAD IMAGES ############\n",
    "file_name_satellite = '../data/kh_ABI_C13.nc'      # Sample satellite image \n",
    "file_name_radar = '../data/kh_MRMS_REFC.nc'        # Corresponding radar image\n",
    "file_name_radar_CNN = '../data/kh_GREMLIN_REFC.nc' # Corresponding CNN estimate of radar (using satellite image as input)\n",
    "\n",
    "selected_samples = range( 0, 200, 50 )\n",
    "#selected_samples = range( 0, 100, 20 )\n",
    "\n",
    "for i_sample in selected_samples:\n",
    "    img_satellite = load_data(file_name_satellite, i_sample)\n",
    "    img_RADAR     = load_data(file_name_radar, i_sample)\n",
    "    img_RADAR_CNN = load_data(file_name_radar_CNN, i_sample)\n",
    "    \n",
    "    radar_image_dict = {\n",
    "        # 'satellite'  : (img_satellite, \"Satellite\"),\n",
    "        #radar_text = print( f'Radar\n",
    "        'radar'      : (img_RADAR, f'Radar_sample_{i_sample}'),\n",
    "        'radar_CNN'  : (img_RADAR_CNN, f'Radar_CNN_sample_{i_sample}'),\n",
    "    }\n",
    "\n",
    "    selected_metrics_univariate = [ \"s1\", \"mgm\", \"tv\", \"grad-tv\", \"fourier-tv\", \"wavelet-tv\" ]\n",
    "    #selected_metrics_univariate = [ \"mgm\", \"tv\", \"grad-tv\", \"fourier-tv\", \"wavelet-tv\", \"s1\" ]\n",
    "    selected_image_keys = [ 'radar', 'radar_CNN' ]\n",
    "    original_image_key = 'radar'\n",
    "    want_uniform_color_scale_per_metric = True\n",
    "    filename_prefix = 'Exp_2_GREMLIN'\n",
    "\n",
    "    apply_univariate_metrics( selected_metrics_univariate, radar_image_dict, selected_image_keys, original_image_key, want_uniform_color_scale_per_metric, filename_prefix )\n",
    "\n",
    "    selected_metrics_bivariate = ['mse', 'mae', 'rmse', 'psnr', 'ncc', 'grad-ds', 'grad-rmse', 'laplace-rmse', 'hist-int', 'hog-pearson', 'fourier-similarity', 'wavelet-similarity']\n",
    "    # Removing fourier-similarity temporarily\n",
    "    selected_metrics_bivariate = ['mse', 'mae', 'rmse', 'psnr', 'ncc', 'grad-ds', 'grad-rmse', 'laplace-rmse', 'hist-int', 'hog-pearson', 'wavelet-similarity']\n",
    "    original_image_key = 'radar'\n",
    "    filename_prefix = 'Exp_2_GREMLIN'\n",
    "    apply_bivariate_metrics( selected_metrics_bivariate, radar_image_dict, selected_image_keys, original_image_key, filename_prefix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c7bd8-73b3-40b2-a2c9-2b0e9084e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore these last two cells.  Not ready to be used yet!\n",
    "\n",
    "#############################################################################\n",
    "# Define a set of noise transformations to be applied to base image.\n",
    "#############################################################################\n",
    "\n",
    "'''\n",
    "def apply_varying_amount_of_noise_to_image( original_img, original_img_string ):\n",
    "    \n",
    "    # Apply transformation 100% of the time (randomness turned off)\n",
    "    rate = 1\n",
    "\n",
    "    selected_sigmas = np.arange(0.0, 1.0, 0.1)   #range( 0.0, 1.0, 0.1 )\n",
    "\n",
    "    transformed_image_dict = { }\n",
    "    \n",
    "    for noise_sigma in selected_sigmas:\n",
    "        \n",
    "        # Add Gaussian Noise to image\n",
    "        my_transform_str = 'noise'\n",
    "        noise_sigma = 0.2   # Choose parameter\n",
    "        noise_string = f'{\"Noise added (sigma=\"}{noise_sigma:.2f}{\"* max)\"}'\n",
    "        noise_img = GaussianNoise(rate, noise=noise_sigma)(original_img)    # Why does this create a modified image even for noise=0?\n",
    "\n",
    "        # Add image to dictionary\n",
    "        key_string = f'noise_{noise_sigma:.1f}'\n",
    "        print(my_string)\n",
    "        transformed_image_dict[key_string] = ( noise_img , noise_string )\n",
    "        \n",
    "\n",
    "    return( transformed_image_dict )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc7843-11d0-451d-bdcc-d40f13c2592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore these last two cells.  Not ready to be used yet!\n",
    "\n",
    "\n",
    "############ EXPERIMENT 3: ############\n",
    "############ Use different amounts of noise ############\n",
    "\n",
    "'''\n",
    "# Available choices: [ 'satellite', 'radar', 'radar_CNN', 'gaussian', 'sinusoidal', 'ridge', 'fractal' ]\n",
    "\n",
    "# Select base image: \n",
    "# Available choices: [ 'satellite', 'radar', 'radar_CNN', 'gaussian', 'sinusoidal', 'ridge', 'fractal' ]\n",
    "base_image_key = 'satellite'\n",
    "(original_img, original_img_string) = base_image_dict[base_image_key]\n",
    "\n",
    "apply_varying_amount_of_noise_to_image( original_img, original_img_string )\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c88ff-fb20-4634-a57f-9f410a885602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
